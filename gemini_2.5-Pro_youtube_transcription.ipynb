{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaquazaCode/gemini_2.5-Pro_video-comprehension-and-YouTube-analysis/blob/main/gemini_2.5-Pro_youtube_transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W-YcjlhWCMF"
      },
      "source": [
        "# Google Gemini 2.5 Pro for YouTube Understanding & Transcription\n",
        "\n",
        "\n",
        "- **Gemini Docs:** [https://ai.google.dev/gemini-api/docs/vision?lang=python#youtube](https://ai.google.dev/gemini-api/docs/vision?lang=python#youtube)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILXfwvlaWCMH"
      },
      "outputs": [],
      "source": [
        "!pip -q install google-genai jinja2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_AI_STUDIO')"
      ],
      "metadata": {
        "id": "geMJrLK2n9vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqvJRd9mWCMH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# create client\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XralEwbfWCMI"
      },
      "source": [
        "## YouTube Example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCzA7tPHWCMJ",
        "outputId": "baeb5bcc-b959-4384-cc3a-ff3819f8ffb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is an analysis of the YouTube video content:\n",
            "\n",
            "1.  **Main Thesis/Claim:** Google's Gemini 2.5 Pro model significantly advances AI capabilities for audio processing tasks like transcription, speaker diarization, and summarization, primarily due to its large output token capacity (64k tokens) and inherent multimodal understanding, making complex audio analysis more practical and powerful than previous models.\n",
            "\n",
            "2.  **Key Topics:**\n",
            "    *   **Gemini 2.5 Pro AI Model:** Focus on its features for audio, especially the 64,000 output token limit enabling transcription of ~2 hours of audio. Comparison to older Gemini models (e.g., 1.5 Pro) and other models like Whisper.\n",
            "    *   **Audio Processing Tasks:**\n",
            "        *   **Transcription:** Generating text from audio.\n",
            "        *   **Speaker Diarization:** Identifying different speakers in the audio and labeling the transcript accordingly (often inferring names if mentioned).\n",
            "        *   **Summarization:** Creating concise summaries (e.g., bullet points with timestamps) from audio transcripts.\n",
            "        *   **Question Answering (Q&A):** Interacting with audio content directly or via its transcript.\n",
            "    *   **Technical Details:** Audio-to-token conversion rates (input/output), pricing considerations (input token limits >200k), supported audio formats (MP3, WAV, FLAC etc.), audio downsampling, stereo-to-mono conversion.\n",
            "    *   **API & Code Implementation (Python):** Using the `google-genai` library, Google AI Studio, File API for uploading audio (`client.files.upload`), generating content (`client.models.generate_content`), prompt engineering techniques (using Jinja2 templates, specifying format, timestamps, speaker handling), and post-processing transcripts (Python code example provided).\n",
            "    *   **Use Cases:** Summarizing podcasts (example: \"My First Million\" downloaded via Podbay.fm), finding specific information/quotes in audio.\n",
            "\n",
            "3.  **Call to Action:**\n",
            "    *   Explicitly asks viewers to \"click like and subscribe\" at the end of the video (15:58).\n",
            "    *   Implicitly encourages viewers to experiment with Gemini 2.5 Pro for their own audio processing needs using the demonstrated techniques and code.\n",
            "\n",
            "4.  **Summary:**\n",
            "    This video explores the enhanced audio processing capabilities of Google's Gemini 2.5 Pro AI model. The creator highlights its large 64k output token limit as a key advantage, allowing for direct transcription of approximately two hours of audio, including speaker diarization. The video demonstrates practical application using Python and the Gemini API, covering audio file uploads, prompt engineering for structured transcripts (with speakers and timestamps), and post-processing for readability. It also showcases creating timestamped summaries from the transcript. The creator argues that Gemini 2.5 Pro represents a significant improvement for tasks like podcast summarization and audio analysis compared to previous models.\n"
          ]
        }
      ],
      "source": [
        "from google.genai import types\n",
        "\n",
        "youtube_url = \"https://www.youtube.com/watch?v=LMhe2egLsrQ\"\n",
        "\n",
        "prompt = \"\"\"Analyze the following YouTube video content. Provide a concise summary covering:\n",
        "\n",
        "1.  **Main Thesis/Claim:** What is the central point the creator is making?\n",
        "2.  **Key Topics:** List the main subjects discussed, referencing specific examples or technologies mentioned (e.g., AI models, programming languages, projects).\n",
        "3.  **Call to Action:** Identify any explicit requests made to the viewer.\n",
        "4.  **Summary:** Provide a concise summary of the video content.\n",
        "\n",
        "Use the provided title, chapter timestamps/descriptions, and description text for your analysis.\"\"\"\n",
        "\n",
        "# Analyze the video\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-pro-exp-03-25\",\n",
        "    contents=types.Content(\n",
        "        parts=[\n",
        "            types.Part(text=prompt),\n",
        "            types.Part(\n",
        "                file_data=types.FileData(file_uri=youtube_url)\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyRoDbEmWCMJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "199ba60e-5da1-443b-d18c-8c1a5c11f32d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here is an analysis of the YouTube video content:\n\n1.  **Main Thesis/Claim:** Google's Gemini 2.5 Pro model significantly advances AI capabilities for audio processing tasks like transcription, speaker diarization, and summarization, primarily due to its large output token capacity (64k tokens) and inherent multimodal understanding, making complex audio analysis more practical and powerful than previous models.\n\n2.  **Key Topics:**\n    *   **Gemini 2.5 Pro AI Model:** Focus on its features for audio, especially the 64,000 output token limit enabling transcription of ~2 hours of audio. Comparison to older Gemini models (e.g., 1.5 Pro) and other models like Whisper.\n    *   **Audio Processing Tasks:**\n        *   **Transcription:** Generating text from audio.\n        *   **Speaker Diarization:** Identifying different speakers in the audio and labeling the transcript accordingly (often inferring names if mentioned).\n        *   **Summarization:** Creating concise summaries (e.g., bullet points with timestamps) from audio transcripts.\n        *   **Question Answering (Q&A):** Interacting with audio content directly or via its transcript.\n    *   **Technical Details:** Audio-to-token conversion rates (input/output), pricing considerations (input token limits >200k), supported audio formats (MP3, WAV, FLAC etc.), audio downsampling, stereo-to-mono conversion.\n    *   **API & Code Implementation (Python):** Using the `google-genai` library, Google AI Studio, File API for uploading audio (`client.files.upload`), generating content (`client.models.generate_content`), prompt engineering techniques (using Jinja2 templates, specifying format, timestamps, speaker handling), and post-processing transcripts (Python code example provided).\n    *   **Use Cases:** Summarizing podcasts (example: \"My First Million\" downloaded via Podbay.fm), finding specific information/quotes in audio.\n\n3.  **Call to Action:**\n    *   Explicitly asks viewers to \"click like and subscribe\" at the end of the video (15:58).\n    *   Implicitly encourages viewers to experiment with Gemini 2.5 Pro for their own audio processing needs using the demonstrated techniques and code.\n\n4.  **Summary:**\n    This video explores the enhanced audio processing capabilities of Google's Gemini 2.5 Pro AI model. The creator highlights its large 64k output token limit as a key advantage, allowing for direct transcription of approximately two hours of audio, including speaker diarization. The video demonstrates practical application using Python and the Gemini API, covering audio file uploads, prompt engineering for structured transcripts (with speakers and timestamps), and post-processing for readability. It also showcases creating timestamped summaries from the transcript. The creator argues that Gemini 2.5 Pro represents a significant improvement for tasks like podcast summarization and audio analysis compared to previous models."
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jinja2 import Template\n",
        "\n",
        "# Generate a structured response using the Gemini API\n",
        "prompt_template = Template(\"\"\"Generate a transcript of the video. Include timestamps and identify speakers.\n",
        "\n",
        "Speakers are:\n",
        "{% for speaker in speakers %}- {{ speaker }}{% if not loop.last %}\\n{% endif %}{% endfor %}\n",
        "\n",
        "eg:\n",
        "[00:00] Brady: Hello there.\n",
        "[00:02] Tim: Hi Brady.\n",
        "\n",
        "It is important to include the correct speaker names. Use the names you identified earlier. If you really don't know the speaker's name, identify them with a letter of the alphabet, eg there may be an unknown speaker 'A' and another unknown speaker 'B'.\n",
        "\n",
        "If there is music or a short jingle playing, signify like so:\n",
        "[01:02] [MUSIC] or [01:02] [JINGLE]\n",
        "\n",
        "If you can identify the name of the music or jingle playing then use that instead, eg:\n",
        "[01:02] [Firework by Katy Perry] or [01:02] [The Sofa Shop jingle]\n",
        "\n",
        "If there is some other sound playing try to identify the sound, eg:\n",
        "[01:02] [Bell ringing]\n",
        "\n",
        "Each individual caption should be quite short, a few short sentences at most.\n",
        "\n",
        "Signify the end of the episode with [END].\n",
        "\n",
        "Don't use any markdown formatting, like bolding or italics.\n",
        "\n",
        "Only use characters from the English alphabet, unless you genuinely believe foreign characters are correct.\n",
        "\n",
        "It is important that you use the correct words and spell everything correctly. Use the context of the podcast to help.\n",
        "If the hosts discuss something like a movie, book or celebrity, make sure the movie, book, or celebrity name is spelled correctly.\"\"\")\n",
        "\n",
        "# Define the speakers and render the prompt\n",
        "speakers = [\"Sam\"]\n",
        "prompt = prompt_template.render(speakers=speakers)"
      ],
      "metadata": {
        "id": "7ZUultwFuktD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze the video\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-pro-exp-03-25\",\n",
        "    contents=types.Content(\n",
        "        parts=[\n",
        "            types.Part(text=prompt),\n",
        "            types.Part(\n",
        "                file_data=types.FileData(file_uri=youtube_url)\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od0XZ-equcVn",
        "outputId": "ea93f8da-c80b-42a9-b223-88f22bbc5210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00] Sam: Okay, so in this video, I want to talk about using the Gemini models, in particular the new Gemini 2.5\n",
            "[00:08] Sam: for doing things with audio. So basically getting transcripts out, getting diarization,\n",
            "[00:14] Sam: being able to do question and answering over audio, etc.\n",
            "[00:19] Sam: And this is a technique that I'm finding myself using more and more, whether I want to summarize a podcast that I don't have time to listen to,\n",
            "[00:28] Sam: right through to automated sort of questioning over audio at scale to be able to find quotes and key information, etc.\n",
            "[00:36] Sam: So how does Gemini 2.5 change the game in this way?\n",
            "[00:40] Sam: At the start, it really wasn't something that Google or DeepMind really posted about. If you come through and look at the\n",
            "[00:46] Sam: initial blog post here, they barely mention audio at all.\n",
            "[00:50] Sam: They just mentioned that this is a high quality multimodal model.\n",
            "[00:53] Sam: And we know that the Gemini models have been multimodal from the start.\n",
            "[00:58] Sam: And certainly last year we were able to basically pass audio into these things with no problem.\n",
            "[01:03] Sam: The big game changer here is that the Gemini 2.5 Pro model actually can generate 64,000 tokens out.\n",
            "[01:12] Sam: And that's compared to the earlier Gemini models, which only were generating say 8,000 tokens out.\n",
            "[01:19] Sam: Now, what does that mean and why is that important?\n",
            "[01:21] Sam: Basically, it works out that if you want to do transcription with one of these models, for about 15 minutes of audio, you're looking at roughly 8,000 tokens.\n",
            "[01:30] Sam: So while the Gemini 1.5 Pro models could do some of these tasks, and the 2.5 is definitely better though.\n",
            "[01:37] Sam: The challenge was not actually the quality of it analyzing, but just being able to get it to generate out the number of tokens needed\n",
            "[01:45] Sam: to do a full transcript of a podcast, etc.\n",
            "[01:49] Sam: Now, with 64,000 tokens, we can generate out roughly two hours of audio transcripts from this.\n",
            "[01:56] Sam: And I'll talk about some tricks that you can do with even longer audio when we get to the code version of this.\n",
            "[02:01] Sam: So just this past week, Google has basically announced the pricing for the 2.50 Pro.\n",
            "[02:07] Sam: And it turns out that it's actually very reasonable when we're looking at the different sizes, etc.\n",
            "[02:12] Sam: So until we see a Flash 2.50, which perhaps will have a much longer generation ability out.\n",
            "[02:19] Sam: This model is certainly the model that I've been using for audio transcripts and audio analysis.\n",
            "[02:25] Sam: And we'll show you a little bit of my pipeline that's what I've been playing around with it when we look at it in code.\n",
            "[02:30] Sam: All right, so if we come and look at the docs, we can see that we can actually use a number of different audio types.\n",
            "[02:35] Sam: So mostly I've been using web files and MP3s.\n",
            "[02:38] Sam: You can certainly use the AAC format or even FLAC files, etc.\n",
            "[02:42] Sam: One of the key things to understand about this\n",
            "[02:44] Sam: is actually when we look at the technical details here, basically for each second of audio, that's going to be 32 tokens in this Gemini model,\n",
            "[02:53] Sam: which translates to 1920 tokens per minute, or roughly about 115,000 tokens per hour of audio.\n",
            "[03:03] Sam: Now, that can be something that you want to think about when you're looking at the pricing being different if it's going to be over 200,000 tokens.\n",
            "[03:12] Sam: You may want to build a pipeline that actually splits, so you're never going over that 200,000 token limit where you've got basically 115,000 going in\n",
            "[03:21] Sam: and say 30 to 40,000 tokens coming out.\n",
            "[03:25] Sam: But if you wanted, you can put in a lot more. Now, obviously, they talk about here that a single prompt can actually have 9.5 hours of audio in there.\n",
            "[03:35] Sam: Like I said, that is fine if you're basically just looking to do some kind of analysis on the audio.\n",
            "[03:41] Sam: If you want to do transcripts though, you're going to find you're probably limited to around two hours,\n",
            "[03:47] Sam: which is going to be 230,000 tokens in and roughly 64,000 tokens out.\n",
            "[03:53] Sam: Now, it's important that you also understand that they basically are downsampling the audio to 16K. Personally, I don't see that as being a big issue.\n",
            "[04:01] Sam: What may be an issue for some people is that it takes stereo sources and bounces them down to a single channel.\n",
            "[04:07] Sam: So if you did have something that you're trying to basically ask the model about positioning in stereo or something, that's not going to work in here.\n",
            "[04:15] Sam: Now, one of the key things to basically get this going is you want to upload the audio file.\n",
            "[04:19] Sam: And you've got two ways of doing that. You can actually just put that in line with the prompt.\n",
            "[04:25] Sam: That probably doesn't make a lot of sense because Gemini is going to limit you to each single call being a maximum of 20 meg.\n",
            "[04:32] Sam: Whereas if you use the upload API, you can upload a single file of two gigabytes and be able to use that.\n",
            "[04:39] Sam: And you can upload multiple files and then use them in one single call as well.\n",
            "[04:44] Sam: We'll look at how to do this in the collab walk through in a bit. But you can see once you've got this uploaded, you can basically then just pass that in as part of the contents\n",
            "[04:53] Sam: that you're going to use to generate new content out.\n",
            "[04:56] Sam: And the model is very good, as we'll see, at being able to generate timestamps out as you go through this.\n",
            "[05:03] Sam: And you can see one of the tricks that I was saying is that if you did want to do something that's longer than two hours,\n",
            "[05:08] Sam: you can upload the audio file, no problem, and just tell it that, okay, I want the transcript to start at X minutes and seconds in\n",
            "[05:17] Sam: and go to X minutes and seconds out.\n",
            "[05:20] Sam: So the model turns out to be quite good at being able to do that as well.\n",
            "[05:23] Sam: Right, let's jump into the code and see how we can actually do all of this.\n",
            "[05:27] Sam: Okay, so looking at the code, I've basically taken some of the examples from the Gemini team and modified it to exactly what I wanted to have in here.\n",
            "[05:36] Sam: So at the start, we're basically just getting the key, etc., and setting up a client.\n",
            "[05:41] Sam: And then this is the original prompt that I took from one of the Gemini DevRel people.\n",
            "[05:46] Sam: You can play around with this prompt. I've started to sort of make my own custom versions, but I've just put their one in here so that you can try this out yourself.\n",
            "[05:53] Sam: I really feel with all these things, you kind of want to think about how your use case may be slightly different,\n",
            "[06:00] Sam: and then try and incorporate that into the prompt. I'm still a big believer of sort of coming up with a generic prompt or taking a generic prompt,\n",
            "[06:08] Sam: and then putting it back into a language model to get the language model to enhance it. So I usually do that with Claude.\n",
            "[06:14] Sam: I've done a whole video about meta prompt with Claude, etc. The same thing can be done with the Gemini models as well.\n",
            "[06:21] Sam: So one of the nice things in here is that it's basically asking it to make a transcript where you're going to have sort of one sentence per line in here.\n",
            "[06:30] Sam: Now, the cool thing is that it can kind of work out who the people are.\n",
            "[06:34] Sam: Now, you can actually put names in here, and it will then use those names.\n",
            "[06:39] Sam: For the podcast that I put in here, it was able to work out the names.\n",
            "[06:43] Sam: I think that happens a lot because the model is actually able to do not only sort of work out what the words are saying, it's actually doing things like audio diarization.\n",
            "[06:53] Sam: So what is audio diarization? Audio diarization is able to work out which speaker is saying what.\n",
            "[07:00] Sam: Now, while it doesn't know the exact name of who is saying what and who is speaking first, etc.\n",
            "[07:07] Sam: It turns out in podcasts when it's two people or a group of people, they tend to address each other by name.\n",
            "[07:14] Sam: So they might say, Sam, what do you think? And then the model is actually smart enough to work out then that the next person talking is probably Sam.\n",
            "[07:22] Sam: And if it gets this over a number of times, it can work it out very well.\n",
            "[07:26] Sam: So traditionally the audio diarization was done through sort of extracting almost like embeddings of each speaker, and then doing a sort of clustering or segmentation, etc.,\n",
            "[07:37] Sam: to work out like which speaker is speaking when.\n",
            "[07:41] Sam: The Gemini model seems to just do this out of the box.\n",
            "[07:44] Sam: And that's pretty amazing that it can do that.\n",
            "[07:47] Sam: Now, if the speakers are not mentioned, you can actually put in the speaker names here as a list of speakers,\n",
            "[07:52] Sam: and it will then try to work out who is who as it goes through.\n",
            "[07:56] Sam: This is especially useful if you've got speakers with names where their spelling is slightly different, etc.\n",
            "[08:03] Sam: All right, so finding the actual podcast or finding somewhere where we can actually download the MP3 is also a challenge. I've looked at a number of different sites,\n",
            "[08:11] Sam: and some of them you can sort of automate so that you can sort of scrape where the link to the MP3 is and then download it.\n",
            "[08:18] Sam: For this video, I've sort of used this site called Podbay FM.\n",
            "[08:21] Sam: And what this allows you to do is basically just come in here and select download file, and then you can download an MP3 of it.\n",
            "[08:30] Sam: So you can see I've basically downloaded the MP3. I've uploaded it into Google Colab.\n",
            "[08:35] Sam: This particular podcast is from the My First Million podcast. And so it's got two people speaking.\n",
            "[08:41] Sam: And you can see I've just uploaded the MP3 there.\n",
            "[08:44] Sam: And if we now run this, we can see that sure enough, it gets uploaded. We've got a name for the file.\n",
            "[08:51] Sam: We've got some information about what it is, when it was created, etc.\n",
            "[08:55] Sam: And it's most important that we keep this uploaded file reference because that's what we're going to pass in to the actual call.\n",
            "[09:03] Sam: So you can see now we once we've done with the uploading, doing the actual call is actually very simple.\n",
            "[09:08] Sam: We're just basically passing it into generate content, pick out the model. In this case, I'm using Gemini 2.5 Pro.\n",
            "[09:15] Sam: And you can see the contents is basically the prompt that we've formatted above and the uploaded file.\n",
            "[09:21] Sam: And you'll see that sure enough, we get back a transcript here. We've got no sort of prefix or anything. We're just getting the raw transcript.\n",
            "[09:29] Sam: Now, that is good in some ways and not so good in other ways.\n",
            "[09:33] Sam: It's good in that, yeah, okay, we're getting like one line, almost sort of like a time stamp for each sentence as we go through here.\n",
            "[09:41] Sam: That's probably not that useful when we've got sort of like these short sentences, and each of them is taking up a whole line and a time stamp.\n",
            "[09:49] Sam: So what I did was basically put together some code. In fact, actually just Gemini 2.5 wrote this for me with me prompting it\n",
            "[09:56] Sam: to basically go through and look for, and it's actually kind of nice because as it had some errors, it basically put the debugging code in there,\n",
            "[10:06] Sam: and I was able to just uncomment this, give it the print statements out. It could see what was not working, and then be able to fix that code up pretty quickly.\n",
            "[10:14] Sam: So the idea here was that we're going to pass in that original text, and we're going to sort of say like, okay, if it's the same speaker speaking,\n",
            "[10:23] Sam: then only give me a timestamp every 30 seconds, or give me a timestamp when the person speaking changes.\n",
            "[10:30] Sam: So you can see when we've got this processed transcript, now I've got a long bit of text with the speaker,\n",
            "[10:36] Sam: and I only get a new timestamp after 30 seconds, but if someone new comes in, even if they're just saying one word like this, okay, we get a new timestamp.\n",
            "[10:45] Sam: And then we back to the sort of another timestamp for the new speaker, and then every 30 seconds.\n",
            "[10:50] Sam: So this simplifies it down a lot so that you've got something which still has got all the diarization detail of knowing who is speaking when,\n",
            "[11:00] Sam: but it's not just doing a timestamp for every single sentence. Now, you could obviously change that. So I put it for every 30 seconds.\n",
            "[11:06] Sam: You could put it for every 60 seconds if you want to basically change what you're getting out here.\n",
            "[11:11] Sam: Now, here's the thing that I've found to work really well. If I wanted to, I could actually just change the prompt\n",
            "[11:19] Sam: and ask questions of the audio directly.\n",
            "[11:22] Sam: For podcasts, once you've got this transcript, though, it doesn't really make a lot of sense to keep using the audio unless you had something where, perhaps they're playing music\n",
            "[11:32] Sam: and they're talking about the music and you want to find out something about the music, that kind of thing.\n",
            "[11:36] Sam: What I tend to do is basically take that transcript, and now I prompt that.\n",
            "[11:42] Sam: And this is a simple prompt that I've come up with. Most welcome to change it. I've got different variations, etc.\n",
            "[11:47] Sam: Here basically saying, make a set of notes in the form of bullet points with the timestamp at the end of each idea in the form of hours, minutes, seconds\n",
            "[11:57] Sam: to summarize this podcast. The bullets should be based on the idea, and don't need to be sequential.\n",
            "[12:02] Sam: So if someone's talking about an idea at one point, and then they come back to it later on, we kind of want like all those collected together.\n",
            "[12:10] Sam: Structure the ideas with headings and subheadings. Don't include any prefix. Here is the transcript below.\n",
            "[12:16] Sam: And then I pass in that transcript that we've just processed to basically get it down. So you can see here we've got this prompt that we've just put in plus the processed transcript.\n",
            "[12:25] Sam: Now I get out a whole summary with a bunch of ideas in here. And you can see each one of them has got the timestamp at the end.\n",
            "[12:34] Sam: So if I do want to go to one of the particular things and check it out, I can actually go to it.\n",
            "[12:42] Sam: Now, it may not be always 100% accurate with these, but I find that it is actually pretty good.\n",
            "[12:47] Sam: With the Gemini 2.5 Pro, it's much better than the old 1.5 used to be at this kind of thing.\n",
            "[12:54] Sam: So you can actually get it to basically give you those timestamps. And then if you wanted to, you could actually code up a UI that could just auto go to those timestamps in the recording.\n",
            "[13:06] Sam: So if you did want to go and check something, like here we want to see, okay, these five roles in any system for wealth creation,\n",
            "[13:12] Sam: we can actually just go to that timestamp and then start going through and looking at it. We can see that each one has got a different timestamp in there.\n",
            "[13:21] Sam: And sure enough, we've got each of these five things laid out, etc.\n",
            "[13:24] Sam: And then if we just come in here, we can actually play the audio file and go through it and look at this. Now, of course, we could put in saving this to a text file,\n",
            "[13:32] Sam: if we want to use it, posting it somewhere, that kind of thing as well.\n",
            "[13:36] Sam: Now, one of the other things I mentioned earlier on is that if the podcast is more than two hours, the challenge is you're not going to have enough tokens to generate all of it out.\n",
            "[13:45] Sam: So what you can do is you can actually just put it in your prompt. I want you to start the transcript at 1 hour 30 minutes into this podcast,\n",
            "[13:55] Sam: and then get the transcript out for that.\n",
            "[13:58] Sam: And then you can use a little bit of fuzzy matching to actually join it. So normally what I would do for that kind of thing is do some kind of overlap where I've got a few minutes overlap\n",
            "[14:07] Sam: of that the first segment is going to end maybe at 1 hour 32. The second segment is going to start at 1 hour 30.\n",
            "[14:15] Sam: And then I know on both of those transcripts, I should have two minutes that kind of overlap, which I can then get it to work out what to cut or something.\n",
            "[14:23] Sam: Now that one you can sort of experiment. Again, the Gemini 2.5 Pro model is just so much better at this now than the old models were.\n",
            "[14:32] Sam: Alright, so just to finish up, if you've got any sort of transcription needs, of course, using raw transcription models is still a useful thing.\n",
            "[14:41] Sam: Though things like Whisper, etc, out of the box don't actually give you that diarization in the way that this kind of can do.\n",
            "[14:50] Sam: And also with AI Studio at the moment, you can actually just make free calls like this. This whole notebook was just two calls.\n",
            "[14:56] Sam: So you can set this up to just go and transcribe the podcasts that you're interested in, the audio interviews that you're interested in,\n",
            "[15:03] Sam: and put this all together so that you've got a set of notes, etc.\n",
            "[15:07] Sam: And you can even prompt it to do things like NotebookLM where it would turn it into a podcast, and then you can send that to a TTS system to make a podcast about a podcast or an abbreviated podcast about a podcast.\n",
            "[15:21] Sam: I think there are lots of fun things that we'll see happening in the future with now the TTS systems being able to copy people's voices,\n",
            "[15:28] Sam: that you may be even able to just take one of the voices off the original recording, have it do the summary for you at the end.\n",
            "[15:35] Sam: Now, of course, you have to be careful of legal issues, etc. This really is a cool way to be able to take audio content and just reduce it to a form that you can consume it much quicker.\n",
            "[15:46] Sam: Anyway, in an upcoming video, I'll also look at doing the same for YouTube videos and some of the techniques that you can use this model for doing YouTube videos as well.\n",
            "[15:55] Sam: Right. As always, if you found the video useful, please click like and subscribe, and I will talk to you in the next video. Bye for now.\n",
            "[16:03] [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def mmss_to_seconds(time_str):\n",
        "  \"\"\"Converts a time string in MM:SS format to the number of seconds.\n",
        "\n",
        "  Args:\n",
        "    time_str: The time string in MM:SS format.\n",
        "\n",
        "  Returns:\n",
        "    The number of seconds represented by the time string, or None if the input is invalid.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    minutes, seconds = map(int, time_str.split(':'))\n",
        "    if minutes < 0 or seconds < 0 or seconds >= 60:\n",
        "      return None  # Handle invalid input\n",
        "    return minutes * 60 + seconds\n",
        "  except ValueError:\n",
        "    return None  # Handle invalid input format\n",
        "\n",
        "\n",
        "def get_youtube_video_id(url):\n",
        "    pattern = r'(?:https?://)?(?:www\\.)?(?:youtube\\.com/(?:watch\\?v=|embed/|v/)|youtu\\.be/)([a-zA-Z0-9_-]{11})'\n",
        "    match = re.search(pattern, url)\n",
        "    return match.group(1) if match else None\n"
      ],
      "metadata": {
        "id": "Zet4jerivN3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "pG9Rhfli8H_0",
        "outputId": "33d9a2d1-eb0a-4d6d-ac99-5898a32393dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x78b54732d410>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"640\"\n",
              "            height=\"360\"\n",
              "            src=\"https://www.youtube.com/embed/LMhe2egLsrQ?start=863\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "image/jpeg": "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\n"
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "\n",
        "time_str = \"14:23\"\n",
        "\n",
        "\n",
        "youtube_id = \"https://www.youtube.com/watch?v=LMhe2egLsrQ\"\n",
        "\n",
        "video_id = get_youtube_video_id(youtube_id)\n",
        "start_time_seconds = mmss_to_seconds(time_str)\n",
        "\n",
        "YouTubeVideo(video_id, width=640, height=360, start=start_time_seconds)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "youtube_url = \"https://www.youtube.com/watch?v=LMhe2egLsrQ\"\n",
        "\n",
        "prompt = \"\"\"Analyze the following YouTube video content. Please extract:\n",
        "\n",
        "1.  Code in that is shown in Colab/Jupyter notebook not in documentation\n",
        "\n",
        "return the code in the format ```code```\n",
        "\"\"\"\n",
        "\n",
        "# Analyze the video\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-pro-exp-03-25\",\n",
        "    contents=types.Content(\n",
        "        parts=[\n",
        "            types.Part(text=prompt),\n",
        "            types.Part(\n",
        "                file_data=types.FileData(file_uri=youtube_url)\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJc_-hhk_uty",
        "outputId": "9f445a1c-950f-4e41-901e-2bade34d6f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "!pip -q install google-genai jinja2\n",
            "```\n",
            "\n",
            "```python\n",
            "from google.colab import userdata\n",
            "GOOGLE_API_KEY=userdata.get('GOOGLE_AI_STUDIO')\n",
            "```\n",
            "\n",
            "```python\n",
            "import os\n",
            "from google import genai\n",
            "from google.genai import types\n",
            "\n",
            "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
            "```\n",
            "\n",
            "```python\n",
            "from jinja2 import Template\n",
            "# Generate a structured response using the Gemini API\n",
            "prompt_template = Template(\"\"\"\\\"\\\"\\\"Generate a transcript of the episode. Include timestamps and identify speakers.\n",
            "\n",
            "Speakers are:\n",
            "{% for speaker in speakers %}- {{ speaker }}{% if not loop.last %}\\n{% endif %}{% endfor %}\n",
            "\n",
            "eg:\n",
            "[00:00] Brady: Hello there.\n",
            "[00:02] Tim: Hi Brady.\n",
            "\n",
            "It is important to include the correct speaker names. Use the names you identified earlier. If there is music or a short jingle playing, signify like so:\n",
            "[01:02] [MUSIC] or [01:02] [JINGLE]\n",
            "\n",
            "If you can identify the name of the music or jingle playing then use that instead, eg:\n",
            "[01:02] [Firework by Katy Perry] or [01:02] [The Sofa Shop jingle]\n",
            "\n",
            "If there is some other sound playing try to identify the sound, eg:\n",
            "[01:02] [Bell ringing]\n",
            "\n",
            "Each individual caption should be quite short, a few short sentences at most.\n",
            "\n",
            "Signify the end of the episode with [END].\n",
            "\n",
            "Don't use any markdown formatting, like bolding or italics.\n",
            "\n",
            "Only use characters from the English alphabet, unless you genuinely believe foreign characters are essential (e.g. names, places).\n",
            "It is important that you use the correct words and spell everything correctly. Use the correct punctuation.\n",
            "If the hosts discuss something like a movie, book or celebrity, make sure the movie, book or celebrity name is correct.\n",
            "\\\"\\\"\\\"\"\"\")\n",
            "\n",
            "# Define the speakers and render the prompt\n",
            "speakers = [\"John\"]\n",
            "prompt = prompt_template.render(speakers=speakers)\n",
            "print(prompt)\n",
            "\n",
            "```\n",
            "\n",
            "```python\n",
            "# path to the file to upload\n",
            "file_path = \"/content/HS4830417304.mp3\"\n",
            "\n",
            "# Upload the file to the File API\n",
            "uploaded_file = client.files.upload(file=file_path)\n",
            "\n",
            "file_name = uploaded_file.name\n",
            "print(file_name)\n",
            "\n",
            "myfile = client.files.get(name=file_name)\n",
            "print(myfile)\n",
            "```\n",
            "\n",
            "```python\n",
            "response = client.models.generate_content(\n",
            "    model=\"gemini-2.5-pro-exp-03-25\",\n",
            "    contents=[prompt, uploaded_file],\n",
            ")\n",
            "\n",
            "print(response.text)\n",
            "```\n",
            "\n",
            "```python\n",
            "import re\n",
            "import datetime\n",
            "\n",
            "def timestamp_to_seconds(ts_str):\n",
            "    \"\"\"Converts an HH:MM:SS or MM:SS timestamp string to total seconds.\"\"\"\n",
            "    # Args:\n",
            "    #   ts_str (str): Timestamp string in HH:MM:SS or MM:SS format.\n",
            "    # Returns:\n",
            "    #   int or None: Total seconds from midnight, or None if parsing fails.\n",
            "    try:\n",
            "        # Remove milliseconds if present\n",
            "        ts_str = ts_str.split('.')[0]\n",
            "        # Split timestamp into parts\n",
            "        parts = list(map(int, ts_str.split(':')))\n",
            "\n",
            "        if len(parts) == 3: # HH:MM:SS format\n",
            "            h, m, s = parts\n",
            "            return h * 3600 + m * 60 + s\n",
            "        elif len(parts) == 2: # MM:SS format\n",
            "            m, s = parts\n",
            "            return m * 60 + s\n",
            "        else:\n",
            "            # Invalid number of parts\n",
            "            return None\n",
            "    except (ValueError, AttributeError, IndexError):\n",
            "        # Return None if parsing fails for any reason\n",
            "        return None\n",
            "\n",
            "def seconds_to_timestamp(total_seconds):\n",
            "    \"\"\"\n",
            "    Converts total seconds to an HH:MM:SS timestamp string.\n",
            "    (No changes needed here, always outputs full format)\n",
            "\n",
            "    Args:\n",
            "      total_seconds (int): Total seconds from midnight.\n",
            "\n",
            "    Returns:\n",
            "      str: Timestamp string in HH:MM:SS format.\n",
            "    \"\"\"\n",
            "    if total_seconds is None or total_seconds < 0:\n",
            "        total_seconds = 0 # Default to 0 if input is invalid or negative\n",
            "    # Calculate hours, minutes, and seconds\n",
            "    hours, remainder = divmod(total_seconds, 3600)\n",
            "    minutes, seconds = divmod(remainder, 60)\n",
            "    # Format as HH:MM:SS with leading zeros\n",
            "    return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n",
            "\n",
            "def process_transcript(input_text, max_segment_duration=30):\n",
            "    \"\"\"\n",
            "    Processes transcript text to join lines based on speaker and time.\n",
            "\n",
            "    Joins consecutive lines if the speaker is the same AND the time elapsed\n",
            "    since the start of the current segment is within max_segment_duration.\n",
            "    Starts a new segment if the speaker changes OR the time limit is exceeded.\n",
            "    Includes non-dialogue lines (like [MUSIC]) as separate lines.\n",
            "\n",
            "    Args:\n",
            "      input_text (str): The raw transcript text (multiline string).\n",
            "      max_segment_duration (int): Maximum duration in seconds for a single\n",
            "                                 speaker's segment before forcing a new\n",
            "                                 timestamp. Defaults to 30.\n",
            "\n",
            "    Returns:\n",
            "      str: The processed transcript text as a multiline string.\n",
            "    \"\"\"\n",
            "    # Use splitlines() for more robust handling of different newline characters\n",
            "    lines = input_text.strip().splitlines()\n",
            "    output_lines = [] # List to store the processed output lines\n",
            "\n",
            "    # Variables to keep track of the current segment being built\n",
            "    current_segment_start_ts_str = None # Timestamp string of the segment start\n",
            "    current_segment_start_seconds = None # Timestamp in seconds of the segment start\n",
            "    current_speaker = None # Speaker of the current segment\n",
            "    current_text_parts = [] # List of text pieces in the current segment\n",
            "\n",
            "    # --- UPDATED Regex ---\n",
            "    # Capture timestamp [HH:MM:SS] or [MM:SS], speaker, and text content.\n",
            "    # Made the HH: part optional using (?:...)?\n",
            "    line_regex = re.compile(r'\\[((?:\\d{2}:)?\\d{2}:\\d{2}(?:\\.\\d+)?)]\\s*([^:]+):\\s*(.*)')\n",
            "\n",
            "\n",
            "    for i, line in enumerate(lines):\n",
            "        line = line.strip() # Remove leading/trailing whitespace\n",
            "        if not line:\n",
            "            continue # Skip empty lines\n",
            "\n",
            "        match = line_regex.match(line)\n",
            "\n",
            "        # --- Debugging Prints (Keep commented unless needed) ---\n",
            "        # print(f'\\nProcessing Line {i+1}: {line}')\n",
            "        # if match:\n",
            "        #     _ts, _spk, _txt = match.groups()\n",
            "        #     _sec = timestamp_to_seconds(_ts)\n",
            "        #     print(f'  Parsed: ts={_ts}, speaker={_spk.strip()}, text=\\'{_txt.strip()}\\'')\n",
            "        #     print(f'  Current Segment State: speaker=\\'{current_speaker}\\', start_ts=\\'{current_segment_start_ts_str}\\', start_sec={current_segment_start_seconds}')\n",
            "        # else:\n",
            "        #     print(f'  No Match: Treating as non-dialogue.')\n",
            "        #     print(f'  Current Segment State: speaker=\\'{current_speaker}\\', start_ts=\\'{current_segment_start_ts_str}\\', start_sec={current_segment_start_seconds}')\n",
            "        # --- End Debugging Prints ---\n",
            "\n",
            "        if not match:\n",
            "            # Handle non-standard lines ---\n",
            "            if current_speaker is not None:\n",
            "                segment_text = ' '.join(filter(None, current_text_parts))\n",
            "                # print(f\"  Finalizing previous (due to non-match): [{current_segment_start_ts_str}] {current_speaker}: {segment_text}\") # DEBUG\n",
            "                output_lines.append(f\"[{current_segment_start_ts_str}] {current_speaker}: {segment_text}\")\n",
            "                current_speaker = None\n",
            "                current_text_parts = []\n",
            "                current_segment_start_ts_str = None\n",
            "                current_segment_start_seconds = None\n",
            "            # print(f\"  Adding non-dialogue line: {line}\") # DEBUG\n",
            "            output_lines.append(line)\n",
            "            continue\n",
            "\n",
            "        # --- Process standard dialogue lines ---\n",
            "        ts_str, speaker, text = match.groups()\n",
            "        speaker = speaker.strip()\n",
            "        text = text.strip()\n",
            "        # Use the updated function to parse timestamp\n",
            "        current_seconds = timestamp_to_seconds(ts_str)\n",
            "\n",
            "        if current_seconds is None:\n",
            "            print(f\"Warning: Skipping line {i+1} due to invalid timestamp format: {line}\")\n",
            "            continue\n",
            "\n",
            "        # --- Logic to decide whether to start a new segment ---\n",
            "        start_new_segment = False\n",
            "        if current_speaker is None: # First line of a new speaker\n",
            "             start_new_segment = True\n",
            "        elif speaker != current_speaker: # Speaker changed\n",
            "             start_new_segment = True\n",
            "        elif current_seconds - current_segment_start_seconds > max_segment_duration: # Time limit exceeded\n",
            "             start_new_segment = True\n",
            "\n",
            "        if start_new_segment:\n",
            "            # Finalize the previous segment if it exists\n",
            "            if current_speaker is not None:\n",
            "                segment_text = ' '.join(filter(None, current_text_parts))\n",
            "                # print(f\"  Finalizing previous: [{current_segment_start_ts_str}] {current_speaker}: {segment_text}\") # DEBUG\n",
            "                output_lines.append(f\"[{current_segment_start_ts_str}] {current_speaker}: {segment_text}\")\n",
            "\n",
            "            # Start the new segment\n",
            "            # print(f\"  Starting new segment: speaker='{speaker}', ts='{ts_str}', sec={current_seconds}\") # DEBUG\n",
            "            current_segment_start_ts_str = seconds_to_timestamp(current_seconds) # Use formatted timestamp\n",
            "            current_segment_start_seconds = current_seconds\n",
            "            current_speaker = speaker\n",
            "            current_text_parts = [text]\n",
            "        else:\n",
            "            # Append text to the current segment\n",
            "            # print(f\"  Appending to current segment: '{text}'\") # DEBUG\n",
            "            current_text_parts.append(text)\n",
            "\n",
            "    # Finalize the last segment after the loop\n",
            "    if current_speaker is not None:\n",
            "        segment_text = ' '.join(filter(None, current_text_parts))\n",
            "        # print(f\"Finalizing last segment: [{current_segment_start_ts_str}] {current_speaker}: {segment_text}\") # DEBUG\n",
            "        output_lines.append(f\"[{current_segment_start_ts_str}] {current_speaker}: {segment_text}\")\n",
            "\n",
            "    return \"\\n\".join(output_lines)\n",
            "\n",
            "```\n",
            "\n",
            "```python\n",
            "processed_transcript = process_transcript(response.text, max_segment_duration=30)\n",
            "print(processed_transcript)\n",
            "```\n",
            "\n",
            "```python\n",
            "PROMPT = \"\"\"\\\"\\\"\\\"Make me a set of notes in the form of bullet points \\\n",
            "(with time stamps at end of each idea (in the form HH:MM:SS)) to summarize this podcast \\\n",
            "The bullets should be based on the idea and don't need to be sequential.\n",
            "Structure the ideas with a heading and subheadings. Don't include any prefix. here is transcript below:\n",
            "\"\"\"\n",
            "\n",
            "response = client.models.generate_content(\n",
            "    model=\"gemini-2.5-pro-exp-03-25\",\n",
            "    contents=[PROMPT + processed_transcript],\n",
            ")\n",
            "\n",
            "print(response.text)\n",
            "```\n",
            "\n",
            "```python\n",
            "import IPython.display as ipd\n",
            "ipd.Audio(\"/content/HS4830417304.mp3\", autoplay=True)\n",
            "\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AwsHhPVTGX0p",
        "outputId": "57661e4f-5aa3-423a-fe52-6f73f87cbecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\n!pip -q install google-genai jinja2\n```\n\n```python\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_AI_STUDIO')\n```\n\n```python\nimport os\nfrom google import genai\nfrom google.genai import types\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n```python\nfrom jinja2 import Template\n# Generate a structured response using the Gemini API\nprompt_template = Template(\"\"\"\\\"\\\"\\\"Generate a transcript of the episode. Include timestamps and identify speakers.\n\nSpeakers are:\n{% for speaker in speakers %}- {{ speaker }}{% if not loop.last %}\\n{% endif %}{% endfor %}\n\neg:\n[00:00] Brady: Hello there.\n[00:02] Tim: Hi Brady.\n\nIt is important to include the correct speaker names. Use the names you identified earlier. If there is music or a short jingle playing, signify like so:\n[01:02] [MUSIC] or [01:02] [JINGLE]\n\nIf you can identify the name of the music or jingle playing then use that instead, eg:\n[01:02] [Firework by Katy Perry] or [01:02] [The Sofa Shop jingle]\n\nIf there is some other sound playing try to identify the sound, eg:\n[01:02] [Bell ringing]\n\nEach individual caption should be quite short, a few short sentences at most.\n\nSignify the end of the episode with [END].\n\nDon't use any markdown formatting, like bolding or italics.\n\nOnly use characters from the English alphabet, unless you genuinely believe foreign characters are essential (e.g. names, places).\nIt is important that you use the correct words and spell everything correctly. Use the correct punctuation.\nIf the hosts discuss something like a movie, book or celebrity, make sure the movie, book or celebrity name is correct.\n\\\"\\\"\\\"\"\"\")\n\n# Define the speakers and render the prompt\nspeakers = [\"John\"]\nprompt = prompt_template.render(speakers=speakers)\nprint(prompt)\n\n```\n\n```python\n# path to the file to upload\nfile_path = \"/content/HS4830417304.mp3\"\n\n# Upload the file to the File API\nuploaded_file = client.files.upload(file=file_path)\n\nfile_name = uploaded_file.name\nprint(file_name)\n\nmyfile = client.files.get(name=file_name)\nprint(myfile)\n```\n\n```python\nresponse = client.models.generate_content(\n    model=\"gemini-2.5-pro-exp-03-25\",\n    contents=[prompt, uploaded_file],\n)\n\nprint(response.text)\n```\n\n```python\nimport re\nimport datetime\n\ndef timestamp_to_seconds(ts_str):\n    \"\"\"Converts an HH:MM:SS or MM:SS timestamp string to total seconds.\"\"\"\n    # Args:\n    #   ts_str (str): Timestamp string in HH:MM:SS or MM:SS format.\n    # Returns:\n    #   int or None: Total seconds from midnight, or None if parsing fails.\n    try:\n        # Remove milliseconds if present\n        ts_str = ts_str.split('.')[0]\n        # Split timestamp into parts\n        parts = list(map(int, ts_str.split(':')))\n\n        if len(parts) == 3: # HH:MM:SS format\n            h, m, s = parts\n            return h * 3600 + m * 60 + s\n        elif len(parts) == 2: # MM:SS format\n            m, s = parts\n            return m * 60 + s\n        else:\n            # Invalid number of parts\n            return None\n    except (ValueError, AttributeError, IndexError):\n        # Return None if parsing fails for any reason\n        return None\n\ndef seconds_to_timestamp(total_seconds):\n    \"\"\"\n    Converts total seconds to an HH:MM:SS timestamp string.\n    (No changes needed here, always outputs full format)\n\n    Args:\n      total_seconds (int): Total seconds from midnight.\n\n    Returns:\n      str: Timestamp string in HH:MM:SS format.\n    \"\"\"\n    if total_seconds is None or total_seconds < 0:\n        total_seconds = 0 # Default to 0 if input is invalid or negative\n    # Calculate hours, minutes, and seconds\n    hours, remainder = divmod(total_seconds, 3600)\n    minutes, seconds = divmod(remainder, 60)\n    # Format as HH:MM:SS with leading zeros\n    return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n\ndef process_transcript(input_text, max_segment_duration=30):\n    \"\"\"\n    Processes transcript text to join lines based on speaker and time.\n\n    Joins consecutive lines if the speaker is the same AND the time elapsed\n    since the start of the current segment is within max_segment_duration.\n    Starts a new segment if the speaker changes OR the time limit is exceeded.\n    Includes non-dialogue lines (like [MUSIC]) as separate lines.\n\n    Args:\n      input_text (str): The raw transcript text (multiline string).\n      max_segment_duration (int): Maximum duration in seconds for a single\n                                 speaker's segment before forcing a new\n                                 timestamp. Defaults to 30.\n\n    Returns:\n      str: The processed transcript text as a multiline string.\n    \"\"\"\n    # Use splitlines() for more robust handling of different newline characters\n    lines = input_text.strip().splitlines()\n    output_lines = [] # List to store the processed output lines\n\n    # Variables to keep track of the current segment being built\n    current_segment_start_ts_str = None # Timestamp string of the segment start\n    current_segment_start_seconds = None # Timestamp in seconds of the segment start\n    current_speaker = None # Speaker of the current segment\n    current_text_parts = [] # List of text pieces in the current segment\n\n    # --- UPDATED Regex ---\n    # Capture timestamp [HH:MM:SS] or [MM:SS], speaker, and text content.\n    # Made the HH: part optional using (?:...)?\n    line_regex = re.compile(r'\\[((?:\\d{2}:)?\\d{2}:\\d{2}(?:\\.\\d+)?)]\\s*([^:]+):\\s*(.*)')\n\n\n    for i, line in enumerate(lines):\n        line = line.strip() # Remove leading/trailing whitespace\n        if not line:\n            continue # Skip empty lines\n\n        match = line_regex.match(line)\n\n        # --- Debugging Prints (Keep commented unless needed) ---\n        # print(f'\\nProcessing Line {i+1}: {line}')\n        # if match:\n        #     _ts, _spk, _txt = match.groups()\n        #     _sec = timestamp_to_seconds(_ts)\n        #     print(f'  Parsed: ts={_ts}, speaker={_spk.strip()}, text=\\'{_txt.strip()}\\'')\n        #     print(f'  Current Segment State: speaker=\\'{current_speaker}\\', start_ts=\\'{current_segment_start_ts_str}\\', start_sec={current_segment_start_seconds}')\n        # else:\n        #     print(f'  No Match: Treating as non-dialogue.')\n        #     print(f'  Current Segment State: speaker=\\'{current_speaker}\\', start_ts=\\'{current_segment_start_ts_str}\\', start_sec={current_segment_start_seconds}')\n        # --- End Debugging Prints ---\n\n        if not match:\n            # Handle non-standard lines ---\n            if current_speaker is not None:\n                segment_text = ' '.join(filter(None, current_text_parts))\n                # print(f\"  Finalizing previous (due to non-match): [{current_segment_start_ts_str}] {current_speaker}: {segment_text}\") # DEBUG\n                output_lines.append(f\"[{current_segment_start_ts_str}] {current_speaker}: {segment_text}\")\n                current_speaker = None\n                current_text_parts = []\n                current_segment_start_ts_str = None\n                current_segment_start_seconds = None\n            # print(f\"  Adding non-dialogue line: {line}\") # DEBUG\n            output_lines.append(line)\n            continue\n\n        # --- Process standard dialogue lines ---\n        ts_str, speaker, text = match.groups()\n        speaker = speaker.strip()\n        text = text.strip()\n        # Use the updated function to parse timestamp\n        current_seconds = timestamp_to_seconds(ts_str)\n\n        if current_seconds is None:\n            print(f\"Warning: Skipping line {i+1} due to invalid timestamp format: {line}\")\n            continue\n\n        # --- Logic to decide whether to start a new segment ---\n        start_new_segment = False\n        if current_speaker is None: # First line of a new speaker\n             start_new_segment = True\n        elif speaker != current_speaker: # Speaker changed\n             start_new_segment = True\n        elif current_seconds - current_segment_start_seconds > max_segment_duration: # Time limit exceeded\n             start_new_segment = True\n\n        if start_new_segment:\n            # Finalize the previous segment if it exists\n            if current_speaker is not None:\n                segment_text = ' '.join(filter(None, current_text_parts))\n                # print(f\"  Finalizing previous: [{current_segment_start_ts_str}] {current_speaker}: {segment_text}\") # DEBUG\n                output_lines.append(f\"[{current_segment_start_ts_str}] {current_speaker}: {segment_text}\")\n\n            # Start the new segment\n            # print(f\"  Starting new segment: speaker='{speaker}', ts='{ts_str}', sec={current_seconds}\") # DEBUG\n            current_segment_start_ts_str = seconds_to_timestamp(current_seconds) # Use formatted timestamp\n            current_segment_start_seconds = current_seconds\n            current_speaker = speaker\n            current_text_parts = [text]\n        else:\n            # Append text to the current segment\n            # print(f\"  Appending to current segment: '{text}'\") # DEBUG\n            current_text_parts.append(text)\n\n    # Finalize the last segment after the loop\n    if current_speaker is not None:\n        segment_text = ' '.join(filter(None, current_text_parts))\n        # print(f\"Finalizing last segment: [{current_segment_start_ts_str}] {current_speaker}: {segment_text}\") # DEBUG\n        output_lines.append(f\"[{current_segment_start_ts_str}] {current_speaker}: {segment_text}\")\n\n    return \"\\n\".join(output_lines)\n\n```\n\n```python\nprocessed_transcript = process_transcript(response.text, max_segment_duration=30)\nprint(processed_transcript)\n```\n\n```python\nPROMPT = \"\"\"\\\"\\\"\\\"Make me a set of notes in the form of bullet points \\\n(with time stamps at end of each idea (in the form HH:MM:SS)) to summarize this podcast \\\nThe bullets should be based on the idea and don't need to be sequential.\nStructure the ideas with a heading and subheadings. Don't include any prefix. here is transcript below:\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.5-pro-exp-03-25\",\n    contents=[PROMPT + processed_transcript],\n)\n\nprint(response.text)\n```\n\n```python\nimport IPython.display as ipd\nipd.Audio(\"/content/HS4830417304.mp3\", autoplay=True)\n\n```"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WtnbpToxPH9S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}